# Azure OpenAI Configuration Template
# Copy this file to .env and fill in your Azure OpenAI details

# =============================================================================
# AI PROVIDER CONFIGURATION
# =============================================================================
LLM_PROVIDER=azure

# =============================================================================
# AZURE OPENAI SETTINGS (Required)
# =============================================================================
# Your Azure OpenAI API key (found in Azure Portal > Your OpenAI Resource > Keys and Endpoint)
AZURE_OPENAI_API_KEY=your_azure_api_key_here

# Your Azure OpenAI endpoint URL (found in Azure Portal > Your OpenAI Resource > Keys and Endpoint)
# Format: https://your-resource-name.openai.azure.com/
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/

# Your deployment name (the name you gave when deploying a model in Azure OpenAI Studio)
# Common examples: gpt-4, gpt-35-turbo, gpt-4-turbo
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4

# Azure OpenAI API version (use the latest stable version)
# See: https://learn.microsoft.com/en-us/azure/ai-services/openai/reference
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================
# Enable debug mode for development (shows detailed logs and API docs)
DEBUG_MODE=false

# Logging level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Database connection string
# SQLite for development (default)
DATABASE_URL=sqlite:///./stories.db
# PostgreSQL for production (uncomment and configure if needed)
# DATABASE_URL=postgresql://username:password@localhost:5432/ai_content_platform

# =============================================================================
# API SETTINGS
# =============================================================================
# Timeout for API calls in seconds
OPENAI_TIMEOUT=120

# Maximum tokens to generate per request
MAX_TOKENS=1000

# Temperature for response randomness (0.0-2.0, lower = more deterministic)
TEMPERATURE=0.7

# =============================================================================
# SECURITY SETTINGS
# =============================================================================
# Allowed CORS origins (comma-separated URLs)
CORS_ORIGINS=["http://localhost:8000","http://127.0.0.1:8000"]

# Maximum request size in bytes (1MB default)
MAX_REQUEST_SIZE=1048576

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
# Path to log file
LOG_FILE_PATH=logs/app.log

# Hours between log file rotation
LOG_ROTATION_HOURS=1

# Days to retain old log files
LOG_RETENTION_DAYS=7

# =============================================================================
# AZURE-SPECIFIC NOTES
# =============================================================================
# 1. Azure OpenAI requires a subscription and approved access
# 2. Create a resource in Azure Portal: https://portal.azure.com
# 3. Deploy a model in Azure OpenAI Studio: https://oai.azure.com
# 4. Use the deployment name (not the model name) in AZURE_OPENAI_DEPLOYMENT_NAME
# 5. Azure provides enterprise features: data privacy, SLA, support
# 6. Billing is based on token usage and committed throughput units

# =============================================================================
# GETTING STARTED WITH AZURE OPENAI
# =============================================================================
# 1. Apply for Azure OpenAI access: https://aka.ms/oai/access
# 2. Create Azure OpenAI resource in Azure Portal
# 3. Deploy a model (e.g., GPT-4) in Azure OpenAI Studio
# 4. Copy the endpoint, key, and deployment name to this file
# 5. Save as .env and start the application